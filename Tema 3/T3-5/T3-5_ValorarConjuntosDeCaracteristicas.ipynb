{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valorar conjuntos de características\n",
    "\n",
    "Hemos visto como hacer selección de caracteristicas evaluando características individualmente.\n",
    "\n",
    "Supongamos ahora que tenemos una tabla de datos que responde a un problema que desconocemos. Este problema es la función XOR (o-exclusivo, *eXclusive-OR*) y, por tanto, la tabla de valores tendrá ejemplos de las 4 posibilidades siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>XOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1     x2    XOR\n",
       "0   True   True  False\n",
       "1   True  False   True\n",
       "2  False   True   True\n",
       "3  False  False  False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tabla_xor = pd.DataFrame(\n",
    "    {'x1' : [True,  True,  False, False],\n",
    "     'x2' : [True,  False, True,  False],\n",
    "     'XOR': [False, True,  True,  False]}\n",
    ")\n",
    "tabla_xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos además que, como los datos no son perfectos, resulta que también tenemos los valores de otras dos características 'r1' y 'r2' que sospechamos que podrían significar algo pero realmente son sólo ruido aleatorio. Así que podríamos tener el siguiente conjunto de datos. No se ha hecho aleatorio para evitar resultados distintos y evitar relaciones casuales mientras se mantiene el ejemplo de un tamaño pequeño para ver sus probabilidades a simple vista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1     x2     r1     r2  clase\n",
       "0   True   True  False  False  False\n",
       "1   True  False   True  False   True\n",
       "2  False   True  False  False   True\n",
       "3  False  False   True  False  False\n",
       "4   True   True   True   True  False\n",
       "5   True  False  False   True   True\n",
       "6  False   True   True   True   True\n",
       "7  False  False  False   True  False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_xor = pd.DataFrame(\n",
    "    {'x1' :  [True,  True,  False, False, True,  True,  False, False],\n",
    "     'x2' :  [True,  False, True,  False, True,  False, True,  False],\n",
    "     'r1' :  [False, True,  False, True,  True,  False, True,  False],\n",
    "     'r2' :  [False, False, False, False, True,  True,  True,  True ],\n",
    "     'clase':[False, True,  True,  False, False, True,  True,  False]}\n",
    ")\n",
    "tabla_xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en todas las características incluida la clase: $$P(\\text{True}) = P(\\text{False}) = 0.5$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x1)=0.5    P(x2)=0.5    P(r1)=0.5    P(r2)=0.5    P(clase)=0.5    "
     ]
    }
   ],
   "source": [
    "caracteristicas = [c for c in tabla_xor]\n",
    "for c in caracteristicas:\n",
    "    print('P({})={}'.format(c, sum(tabla_xor[c]) / len(tabla_xor)), end='    ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ademas, la probabilidad de que la clase sea cierta condicionada a cada una de las características es también: $$P(clase|x_1=\\text{True}) = P(clase|x_2=\\text{True}) = P(clase|r_1=\\text{True}) = P(clase|x_2=\\text{True}) = 0.5$$\n",
    "y, por extensión de lo anterior, la probabilidad de que la clase sea falsa condicionada a cada una de las características es también 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(clase|x1)=0.5    P(clase|x2)=0.5    P(clase|r1)=0.5    P(clase|r2)=0.5    P(clase|clase)=1.0    "
     ]
    }
   ],
   "source": [
    "for c in caracteristicas:\n",
    "    condicionados = []\n",
    "    for i in range(len(tabla_xor[c])):\n",
    "        if tabla_xor[c][i]:\n",
    "            condicionados.append( (tabla_xor[c][i], tabla_xor['clase'][i]) )\n",
    "    print('P(clase|{})={}'.format(c, \n",
    "                                  len([c for c in condicionados if c == (True, True)]) / len(condicionados)), \n",
    "          end='    ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior quiere decir que la clase es estadísticamente independiente de cada una de las características. Para rizar más el rizo, en este ejemplo hemos hecho que todas las características sean independientes entre sí (como ocurriría si fuesen aleatorias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(x1|x1)=1.0    P(x1|x2)=0.5    P(x1|r1)=0.5    P(x1|r2)=0.5    \n",
      "P(x2|x1)=0.5    P(x2|x2)=1.0    P(x2|r1)=0.5    P(x2|r2)=0.5    \n",
      "P(r1|x1)=0.5    P(r1|x2)=0.5    P(r1|r1)=1.0    P(r1|r2)=0.5    \n",
      "P(r2|x1)=0.5    P(r2|x2)=0.5    P(r2|r1)=0.5    P(r2|r2)=1.0    \n"
     ]
    }
   ],
   "source": [
    "for dependiente in caracteristicas[:-1]:\n",
    "    for c in caracteristicas[:-1]:\n",
    "        condicionados = []\n",
    "        for i in range(len(tabla_xor[c])):\n",
    "            if tabla_xor[c][i]:\n",
    "                condicionados.append( (tabla_xor[c][i], tabla_xor[dependiente][i]) )\n",
    "        print('P({}|{})={}'.format(dependiente, \n",
    "                                   c, \n",
    "                                   len([c for c in condicionados if c == (True, True)]) / len(condicionados)), \n",
    "              end='    ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, este problema parece una pesadilla para la selección de características. De hecho, cualquier medida de características que sólo use los valores de una característica fallará estrepitosamente. Sin embargo, nosotros sabemos que el problema tiene solución y que con las características $x_1$ y $x_2$ se puede conseguir un 100% de acierto.\n",
    "\n",
    "Entonces, podemos concluir que necesitamos medidas que consideren varias características juntas. Estas serán las medidas sobre conjuntos de características que veremos a continuación.\n",
    "\n",
    "## Medidas basadas en consistencia\n",
    "\n",
    "Miden la utilidad de un conjunto de características según lo cerca es este conjunto está de conseguir clasificar acertadamente todos los ejemplos. Esto es: cómo de lejos estamos de poder distinguir las clases con esas caracteristicas. Para ello pueden contarse los ejemplos que no se pueden diferenciar. Por ejemplo, si tenemos:\n",
    "\n",
    "|x1 | r1 | clase |\n",
    "|---|----|-------|\n",
    "|T  | F  | T     |\n",
    "|T  | F  | F     |\n",
    "\n",
    "Vemos que hay dos ejemplos iguales en las caracteríticas seleccionadas (x1 y r1 en este ejemplo) pero con distinto valor para la clase. Aquí, la de los pares de ejemplos inconsistentes (IEP) contaría un par de ejemplos inconsistentes. La medida de Liu (o EI, de los Ejemplos Inconsistentes) consideraría que hay 1 ejemplo mal clasificado (el otro estará bien). La basada en la teoría de conjuntos rugosos contaría 2 ejemplos mal, ya que no sabemos realmente nada de ninguno de los dos. \n",
    "\n",
    "**Lectura**: Lee el siguiente artículo para ver la definición completa de las medidas de consistencia y la justificación de la implementación que haremos a continuación.\n",
    "\n",
    "[Arauzo-Azofra, A., Benitez, J. M., & Castro, J. L. (2008). Consistency measures for feature selection. Journal of Intelligent Information Systems, 30(3), 273-292.](https://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/0824_2008-arauzo-JIIS.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def inconsistent_examples(seleccionadas, objetivo, tabla):\n",
    "    \"\"\"\n",
    "    Ratio de inconsistencia (Liu et al., 1998),\n",
    "     valorado en el rango [0,1[ (0 = completamente consistente)\n",
    "    \"\"\"\n",
    "    x, y = tabla[seleccionadas], tabla[[objetivo]]\n",
    "\n",
    "    # Contar ejemplos de cada patron\n",
    "    tabla_hash = collections.defaultdict(collections.Counter)\n",
    "    for ejemplo, obj in zip(x.itertuples(), y.itertuples()):\n",
    "        tabla_hash[tuple(ejemplo[1:])][obj[1]] += 1\n",
    "\n",
    "    # Calcular ejemplos inconsistentes (clases minoritarias en cada patrón)\n",
    "    contador_inc = 0\n",
    "    for ej in tabla_hash:\n",
    "        total = sum(tabla_hash[ej].values())\n",
    "        clase_mayoritaria = tabla_hash[ej].most_common(1)[0][1]\n",
    "        contador_inc += total - clase_mayoritaria\n",
    "\n",
    "    return contador_inc / len(tabla.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al pasarle las dos características que determinan bien la clase la consistencia es total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inconsistent_examples(['x1', 'x2'], 'clase', tabla_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio si le pasamos un conjunto de las aleatorias, detecta inconsistencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inconsistent_examples(['r1', 'r2'], 'clase', tabla_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y cualquier conjunto que incluya las características que determinan la clase también será consistente. Esto se cumple por la propiedad de la monotonicidad que menciona el artículo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inconsistent_examples(['x1', 'x2', 'r1', 'r2'], 'clase', tabla_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: implementar la medida RSC. Está definida formalmente en el artículo anterior (\"Consistency measures for feature selection\"). Pista, por si esa definición resulta dificil de entender: cuando en un grupo hay algún ejemplo conflicitivo se cuenta como que todos son inconsistentes.\n",
    "\n",
    "**Ejercicio (avanzado, opcional)**: implementar la medida IEP. Se puede hacer con el mismo esquema de las otras pero hay que contar el número de pares de ejemplos inconsistentes que se generan en cada grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de arriba usa tablas hash y funciona muy bien con menos de 100 características seleccionadas. En el siguiente artículo teneis más información sobre la implementación eficiente de estas medidas, con optimizaciones para cuando se van a usar repetidamente sobre los mismos datos. Os puede interesar por lo menos echar un vistazo a su Fig. 19.\n",
    "\n",
    "[Arauzo-Azofra, A., Jiménez-Vílchez, A., Molina-Baena, J., & Luque-Rodriguez, M. (2019). Algorithmic cache of sorted tables for feature selection. Data Mining and Knowledge Discovery, 33(4), 964-994.](https://www.researchgate.net/profile/Antonio-Arauzo-Azofra/publication/331990030_Algorithmic_cache_of_sorted_tables_for_feature_selection/links/5ca4ce58a6fdcc12ee911191/Algorithmic-cache-of-sorted-tables-for-feature-selection.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de información\n",
    "\n",
    "Basadas en la [teoría de la información de Shanon](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n) se pueden generar varias medidas para conjuntos de caracteristicas. Vamos a ver como ejemplo la principal (de la que derivan las demás), la medida de la [información mútua](https://es.wikipedia.org/wiki/Informaci%C3%B3n_mutua) que aportan las características seleccionadas sobre la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def informacion_mutua(seleccionadas, objetivo, tabla):\n",
    "    \"\"\"\n",
    "    Información mútua de Shannon\n",
    "    \"\"\"\n",
    "    x, y = tabla[seleccionadas], tabla[[objetivo]]\n",
    "\n",
    "    # Contar ejemplos de cada patron\n",
    "    tabla_hash = collections.defaultdict(collections.Counter)\n",
    "    for ejemplo, obj in zip(x.itertuples(), y.itertuples()):\n",
    "        tabla_hash[tuple(ejemplo[1:])][obj[1]] += 1    \n",
    "    \n",
    "    # Suma las cuentas de las clases para obtener P(C)\n",
    "    class_counter = collections.Counter()\n",
    "    for ej in tabla_hash:\n",
    "        class_counter += tabla_hash[ej]\n",
    "\n",
    "    n = len(y)\n",
    "\n",
    "    # H(class)\n",
    "    hc = 0\n",
    "    for _, c in class_counter.items():\n",
    "        p = float(c) / n\n",
    "        if p > 0:\n",
    "            hc += - p * math.log(p, 2)\n",
    "\n",
    "    # H(class|selection)\n",
    "    hc_s = 0\n",
    "    for ex, ex_class_counter in tabla_hash.items():\n",
    "        s_count = sum(ex_class_counter.values())\n",
    "        h = 0\n",
    "        for _, c in ex_class_counter.items():\n",
    "            p = float(c) / s_count\n",
    "            if p > 0:\n",
    "                h += p * math.log(p, 2)\n",
    "\n",
    "        hc_s += - ( float(s_count) / n ) * h\n",
    "\n",
    "    # I(S,C) = H(C) - H(C|S)\n",
    "    return hc - hc_s\n",
    "\n",
    "informacion_mutua(['x1', 'r2'], 'clase', tabla_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informacion_mutua(['x1', 'x2'], 'clase', tabla_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrategia envolvente\n",
    "\n",
    "Otra forma de evaluar conjuntos de caracteristicas que es muy empleada es la llamada estrategia envolvente. Utilizar el mismo algoritmo de aprendizaje que se usará luego, para usar su rendimiento sobre el conjunto de características como la valoración de ese conjunto. Para evitar un sobre-ajuste se realiza una particion de los datos usando una parte para entrenar (*train*) y otra para valorar el rendimiento (*test*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def envolvente(seleccionadas, objetivo, tabla):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tabla[seleccionadas], \n",
    "                                                        tabla[objetivo], test_size=0.33)\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred, normalize=True)\n",
    "\n",
    "envolvente(['x1', 'r2'], 'clase', tabla_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envolvente(['x1', 'x2'], 'clase', tabla_xor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
